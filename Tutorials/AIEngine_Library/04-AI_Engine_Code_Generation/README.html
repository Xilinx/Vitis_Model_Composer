
<html>
<head>
<title></title>
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>
<table class="sphinxhide" width="100%">
<html>    
<script>
function myFunction() {

var path = document.location.pathname;
var directory1 = path.substring(path.indexOf('/'), path.lastIndexOf('/'));
var directory = directory1.substring(directory1.lastIndexOf('/')+1); 

commandURI="matlab:XmcExampleApi.changeDirectory('" + directory + "');"

document.location=commandURI
}
</script>
<noscript>Sorry, your browser does not support JavaScript!</noscript>
       
<button type="button" style="background-color:#d0d028; font-size: 20px;" onclick="myFunction()">Open Lab Directory</button>  
              
</html>
<tr width="100%">
<td align="center"><img src="https://raw.githubusercontent.com/Xilinx/Image-Collateral/main/xilinx-logo.png" width="30%"/><h1>AI Engine Development</h1>
<a href="https://www.xilinx.com/products/design-tools/vitis.html">See Vitis™ Development Environment on xilinx.com</br></a>
<a href="https://www.xilinx.com/products/design-tools/vitis/vitis-ai.html">See Vitis™ AI Development Environment on xilinx.com</a>
</td>
</tr>
</table>
<h1 id="lab-4-ai-engine-code-generation-and-cycle-approximate-simulation">Lab 4: AI Engine Code Generation and Cycle-Approximate Simulation</h1>
<p>This lab shows how to use Vitis Model Composer to generate AI Engine graph code and simulate an AI Engine design.</p>
<p>:warning: This AI Engine Lab can be done only in a Linux environment.</p>
<h3 id="procedure">Procedure</h3>
<p>This lab has the following steps:</p>
<ul>
<li>In Step 1, you will use Vitis Model Composer to generate AI Engine graph code for the decimation filter chain design.</li>
<li>In Step 2, you will simulate the design using the AI Engine Simulator and review the design's estimated throughput.</li>
<li>In Step 3, you will review design artifacts generated by Vitis Model Composer and see how they can help integrate the AI Engine kernel with a larger design.</li>
</ul>
<h2 id="step-1-generate-ai-engine-graph-code">Step 1: Generate AI Engine Graph Code</h2>
<p>In this step, you will generate and review graph code for the decimation filter chain.</p>
<ol>
<li><p>Run the <strong><em>setupLab4</em></strong> script to initialize a working directory.</p></li>
<li><p>Open the model <code>Lab4_Start.slx</code>.</p></li>
<li><p>Select the four AIE FIR Filters and the FreqShift block and type <strong><em>Ctrl+G</em></strong> to group them in a subsystem. Assign a new name: <strong>FIRchain</strong>.</p></li>
<li><p>Click the canvas and type <strong><em>model co</em></strong>. Select the Vitis Model Composer Hub block.</p></li>
<li><p>Double-click the Model Composer Hub block. </p></li>
<li><p>On the <strong>Hardware Selection</strong> tab, click the <strong>…</strong> button next to Select Hardware to open the Device Chooser.</p></li>
<li><p>Type <strong><em>xcvc1902</em></strong> into the Search box.</p></li>
<li><p>Select the first device on the list (beginning with <strong><em>xcvc1902</em></strong>) and click <strong>OK</strong>.</p></li>
<li><p>Back in the Vitis Model Composer Hub block, on the Code Generation tab, select the FIRchain subsystem and set the following parameters on the AIE Settings tab:</p>
<ul>
<li>Check <strong>Create testbench</strong>.</li>
<li>Check <strong>Run cycle-approximate AIE Simulation after code generation</strong>.</li>
<li>Check <strong>Plot AIE Simulation Output and Estimate Throughput</strong>.</li></ul></li>
<li><p>Click <strong>Apply</strong>.</p></li>
<li><p>Click <strong>Generate</strong>.</p></li>
</ol>
<p>The Simulink model is run to generate the testbench, then the AI Engine graph code is generated and compiled. The source code can be viewed in <code>./code/src_aie/FIRchain.h</code>.</p>
<p>Let's review this code:</p>
<pre><code class="C++ language-C++">#ifndef __XMC_FIRCHAIN_H__
#define __XMC_FIRCHAIN_H__

#include &lt;adf.h&gt;
#include "./FIR_Halfband_Decimator_f290cd69/FIR_Halfband_Decimator_f290cd69.h"
#include "./FIR_Halfband_Decimator_9d303e82/FIR_Halfband_Decimator_9d303e82.h"
#include "./FIR_Halfband_Decimator_e4b5f201/FIR_Halfband_Decimator_e4b5f201.h"
#include "./FIR_Symmetric_5c1535c2/FIR_Symmetric_5c1535c2.h"
#include "FreqShift.h"
</code></pre>
<p>The graph is defined as a class derived from the class <code>adf::graph</code>. The class definition declares the four FIR filters and our custom FreqShift kernel:</p>
<pre><code class="C++ language-C++">class FIRchain_base : public adf::graph {
public:
FIR_Halfband_Decimator_f290cd69 FIR_Halfband_Decimator;
FIR_Halfband_Decimator_9d303e82 FIR_Halfband_Decimator1;
FIR_Halfband_Decimator_e4b5f201 FIR_Halfband_Decimator2;
FIR_Symmetric_5c1535c2 FIR_Symmetric;
adf::kernel FreqShift_0;
</code></pre>
<p>The graph class constructor instantiates an input port, an output port, and the FreqShift kernel (with a <code>FRAME_LENGTH</code> of 256). Because the FIR filters come from the DSP Library, they are instantiated in their own source files.</p>
<pre><code class="C++ language-C++">public:
adf::input_port In1;
adf::output_port Out1;

FIRchain_base() {
// create kernel FreqShift_0
FreqShift_0 = adf::kernel::create(FreqShift&lt;256&gt;);
adf::source(FreqShift_0) = "FreqShift.cpp";
</code></pre>
<p>The graph class constructor also specifies a runtime <em>constraint</em> on the FreqShift kernel. We will talk more about constraints in Lab 5. This constraint states that the kernel can be expected to use 90% of an AI Engine tile's compute resources, so the <code>aiecompiler</code> should assign this kernel to its own tile.</p>
<pre><code class="C++ language-C++">      // create kernel constraints FreqShift_0
adf::runtime&lt;ratio&gt;(FreqShift_0) = 0.9;
</code></pre>
<p>The <code>adf::connect</code> function describe how components of the graph connect together. These lines of code reproduce the layout of the decimation filter chain from the Simulink model, connecting the output of one block to the input of the next block.</p>
<pre><code class="C++ language-C++">      // create nets to specify connections
adf::connect net0 (In1, FIR_Halfband_Decimator.in[0]);
adf::connect net1 (FIR_Halfband_Decimator.out[0], FIR_Halfband_Decimator1.in[0]);
adf::connect net2 (FIR_Halfband_Decimator1.out[0], FIR_Halfband_Decimator2.in[0]);
adf::connect net3 (FIR_Halfband_Decimator2.out[0], FIR_Symmetric.in[0]);
adf::connect net4 (FIR_Symmetric.out[0], FreqShift_0.in[0]);
adf::dimensions(FreqShift_0.in[0]) = {256};
adf::connect net5 (FreqShift_0.out[0], Out1);
adf::dimensions(FreqShift_0.out[0]) = {256};
}
};
</code></pre>
<p>The graph constructor is wrapped by another graph class that places PLIOs (Programmable Logic Input/Output) on each input and output. PLIOs establish stream connections between the AI Engine and Programmable Logic. PLIOs can be 32, 64, or 128 bits wide; the PLIO width determines how much data is transferred on each clock cycle. The default PLIO width generated by Vitis Model Composer is 32 bits. Later, we will see how to use Vitis Model Composer to change the PLIO width as a way to increase design throughput.</p>
<p>The <code>input_plio</code> and <code>output_plio</code> objects allow you to specify text files to use for input and output to the <code>aiesimulator</code>. Vitis Model Composer has automatically generated an input text file and will parse the output when the simulation completes.</p>
<pre><code class="C++ language-C++">class FIRchain : public adf::graph {
public:
FIRchain_base mygraph;

public:
adf::input_plio In1;
adf::output_plio Out1;

FIRchain() {
In1 = adf::input_plio::create("In1",
adf::plio_32_bits,
"./data/input/In1.txt");

Out1 = adf::output_plio::create("Out1",
adf::plio_32_bits,
"Out1.txt");

adf::connect&lt; &gt; (In1.out[0], mygraph.In1);
adf::connect&lt; &gt; (mygraph.Out1, Out1.in[0]);
}
};

#endif // __XMC_FIRCHAIN_H__
</code></pre>
<h2 id="step-2-review-ai-engine-simulation-results">Step 2: Review AI Engine Simulation Results</h2>
<h3 id="functional-verification">Functional Verification</h3>
<p>Because we selected <strong>Create Testbench</strong> in the Model Composer Hub block, Vitis Model Composer generates a testbench that compares the output of the AI Engine simulation to the Simulink simulation for the same input. The AI Engine simulation runs immediately after testbench generation because we selected the option in the Model Composer Hub block. In this case, the simulation results <strong>MATCH</strong> and the testbench <strong>PASSED</strong>. </p>
<p>The Progress window displays the progress generating and compiling the AI Engine code. It also displays the final result of running the AI Engine simulation:</p>
<p><img src="Images/Image03.png" alt="missing image" /></p>
<p>Regarding the simulation results, there are 3 possible outcomes:</p>
<ul>
<li><strong>Match:</strong> All of the outputs of the Simulink simulation and AI Engine simulation exactly match. In this case, the testbench will <strong>PASS</strong>.</li>
<li><strong>Partial Match:</strong> The outputs of the Simulink simulation and AI Engine simulation match, but either the Simulink output or the AI Engine simulator output produced extra samples that are not accounted for in the other output. This can occur because there is not a direct link between the stop time in Simulink and the <code>aiesimulator</code>'s timeout in cycles. In this case, the testbench will <strong>PASS</strong>.</li>
<li><strong>Do Not Match:</strong> There is a difference between the output of the Simulink simulation and the AI Engine simulation. In this case, the testbench will <strong>FAIL</strong>.</li>
</ul>
<h3 id="estimating-throughput">Estimating Throughput</h3>
<p>The <code>aiesimulator</code> is cycle-approximate, which means it can be used to estimate throughput of the AI Engine design. Because we selected <strong>Plot AIE Simulation Output and Estimate Throughput</strong> in the Model Composer Hub block, after simulation the Simulation Data Inspector opens and is populated with the results of the <code>aiesimulator</code>. </p>
<ol>
<li>In the Simulation Data Inspector window, select the <strong>Out1</strong> signal from the Inspect menu.</li>
</ol>
<p><img src="Images/Image04.png" alt="missing image" /></p>
<p>The output of the AI Engine is plotted in the Simulation Data Inspector. The Simulation Data Inspector also contains a estimate of the AI Engine's throughput. The throughput is calculated by counting the number of output data points and dividing by the total time displayed on the X-axis. </p>
<p>In this case, three frames are received but only two interframe idle time are taken into account. To obtain a more accurate throughput estimate, we can use data cursors to select a specific time region over which to calculate throughput.</p>
<ol start="2">
<li><p>Select the Cursor icon from the toolbar, then select <strong>Two Cursors</strong>. <img src="Images/Image05.png" alt="missing image" /></p></li>
<li><p>Position the cursors at the beginning of the first and third signal frames, as shown below.</p></li>
</ol>
<p><img src="Images/Image06.png" alt="missing image" /></p>
<p>This limits the throughput calculation to the area between the two cursors. In the figures above, the calculated throughput changes from 55 MSPS to 35 MSPS (your displayed value may vary slightly). This throughput is below our expected throughput for the decimation chain, which we expect to output samples at a rate of 125 MSPS. We will see how to improve the throughput in Lab 5.</p>
<h2 id="step-3-review-code-generation-artifacts">Step 3: Review Code Generation Artifacts</h2>
<p>When you generate AI Engine code with Vitis Model Composer, a number of artifacts are also generated. These artifacts can be used to run the AI Engine simulation outside of Vitis Model Composer or to integrate the generated code within a larger project.</p>
<p>The artifacts include shell scripts and Makefiles for compiling, simulating, and building the AI Engine application. Makefiles are commonly used to build applications targeting Versal Adaptive SoC devices. For an example build flow that uses Makefiles, see the <a href="https://github.com/Xilinx/Vitis-Tutorials/tree/2023.1/Developer_Contributed/01-Versal_Custom_Thin_Platform_Extensible_System">Versal Custom Thin Platform</a>. </p>
<p><img src="Images/Image07.png" alt="missing image" /></p>
<ul>
<li><code>data/input/In1.txt</code>, <code>data/reference_output/Out1.txt</code>: These are the input data and reference output data files, respectively, to be used with the <code>aiesimulator</code>. These are simple text files where each row represents inputs/outputs for a simulation time stamp, and each column represents a different channel of data (or for complex data, the real and imaginary components of the data). These files are generated based on the inputs and outputs from the Simulink model.</li>
<li><code>run_hw</code>: This folder contains scripts and Makefiles to run the design on hardware (Hardware Validation flow).<ul>
<li><code>run_hw/run_hw.sh</code>: This script configures the shell environment before launching the Hardware Validation Makefile described below.</li>
<li><code>run_hw/Makefile</code>: The Hardware Validation Makefile executes a full compilation, linking, and packaging process to run a validation testbench of the design using either hardware emulation or real hardware. The Hardware Validation flow will be covered in more detail in Lab 6.</li></ul></li>
<li><code>src_aie</code>: This folder contains the generated source code for the AI Engine graph.</li>
<li><code>src_pl_datamover</code>: This folder contains HLS kernels to move data between the AI Engine and the PL. Used as part of the Hardware Validation flow.</li>
<li><code>src_ps</code>: This folder contains source code for a PS application to run the validation testbench (data movers and AI Engine design) on Versal hardware. Used as part of the Hardware Validation flow.</li>
<li><code>FIRchain.cfg</code>: Vitis compiler link configuration file. This describes how the data movers and AI Engine are to be connected in the design running on hardware. For more information on this file, refer to <a href="https://docs.xilinx.com/r/en-US/ug1076-ai-engine-environment/Linking-the-System">Linking the System</a> in AI Engine Tools and Flows User Guide (UG1076). </li>
<li><code>make.sh</code>: This script configures the shell environment before launching the Makefile described below.</li>
<li><code>Makefile</code>: This Makefile compiles and simulates the AI Engine kernel portion of the design.</li>
</ul>
<p>To reproduce Steps 1 &amp; 2 of this lab outside of Vitis Model Composer, you can <code>cd</code> to the <code>code</code> folder and execute <code>./make.sh</code> from a bash shell. This script requires an environment variable named <code>XILINX_VITIS</code> to point to the Vitis installation location, such as <code>/opt/Xilinx/Vitis/2022.2</code>.</p>
<p>You can also study and modify the generated Makefiles to incorporate the generated AI Engine code as part of a larger Versal Adaptive SoC design.</p>
<h2 id="conclusion">Conclusion</h2>
<p><strong>Congratulations!</strong> This concludes Lab 4. In this lab, you generated AI Engine graph code from Vitis Model Composer, reviewed AI Engine simulation results, and learned about the code generation artifacts produced by Vitis Model Composer. The AI Engine simulation results showed that the design currently does not produce the desired throughput. </p>
<p>In the next lab, you will see how to increase the design's throughput with PLIOs and AI Engine design constraints.</p>
<hr />
<p>&copy; Copyright 2023 Advanced Micro Devices, Inc.</p>
<p>Licensed under the Apache License, Version 2.0 (the "License");<br />
you may not use this file except in compliance with the License.<br />
You may obtain a copy of the License at</p>
<pre><code>    http://www.apache.org/licenses/LICENSE-2.0
</code></pre>
<p>Unless required by applicable law or agreed to in writing, software<br />
distributed under the License is distributed on an "AS IS" BASIS,<br />
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.<br />
See the License for the specific language governing permissions and<br />
limitations under the License.</p>
<p align="center"><sup>XD058 | &copy; Copyright 2023 Advanced Micro Devices, Inc.</sup></p>

</div>
<style type='text/css'>body {
font: 400 16px/1.5 "Helvetica Neue", Helvetica, Arial, sans-serif;
color: #111;
background-color: #fdfdfd;
-webkit-text-size-adjust: 100%;
-webkit-font-feature-settings: "kern" 1;
-moz-font-feature-settings: "kern" 1;
-o-font-feature-settings: "kern" 1;
font-feature-settings: "kern" 1;
font-kerning: normal;
padding: 30px;
}

@media only screen and (max-width: 600px) {
body {
padding: 5px;
}

body > #content {
padding: 0px 20px 20px 20px !important;
}
}

body > #content {
margin: 0px;
max-width: 900px;
border: 1px solid #e1e4e8;
padding: 10px 40px;
padding-bottom: 20px;
border-radius: 2px;
margin-left: auto;
margin-right: auto;
}

hr {
color: #bbb;
background-color: #bbb;
height: 1px;
flex: 0 1 auto;
margin: 1em 0;
padding: 0;
border: none;
}

/**
* Links
*/
a {
color: #0366d6;
text-decoration: none; }
a:visited {
color: #0366d6; }
a:hover {
color: #0366d6;
text-decoration: underline; }

pre {
background-color: #f6f8fa;
border-radius: 3px;
font-size: 85%;
line-height: 1.45;
overflow: auto;
padding: 16px;
}

/**
* Code blocks
*/

code {
background-color: rgba(27,31,35,.05);
border-radius: 3px;
font-size: 85%;
margin: 0;
word-wrap: break-word;
padding: .2em .4em;
font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
}

pre > code {
background-color: transparent;
border: 0;
display: inline;
line-height: inherit;
margin: 0;
overflow: visible;
padding: 0;
word-wrap: normal;
font-size: 100%;
}


/**
* Blockquotes
*/
blockquote {
margin-left: 30px;
margin-top: 0px;
margin-bottom: 16px;
border-left-width: 3px;
padding: 0 1em;
color: #828282;
border-left: 3px solid #e8e8e8;
padding-left: 15px;
font-size: 18px;
letter-spacing: -1px;
font-style: italic;
}
blockquote * {
font-style: normal !important;
letter-spacing: 0;
color: #6a737d !important;
}

/**
* Tables
*/
table {
border-spacing: 2px;
display: block;
font-size: 14px;
overflow: auto;
width: 100%;
margin-bottom: 16px;
border-spacing: 0;
border-collapse: collapse;
}

td {
padding: 6px 13px;
border: 1px solid #dfe2e5;
}

th {
font-weight: 600;
padding: 6px 13px;
border: 1px solid #dfe2e5;
}

tr {
background-color: #fff;
border-top: 1px solid #c6cbd1;
}

table tr:nth-child(2n) {
background-color: #f6f8fa;
}

/**
* Others
*/

img {
max-width: 100%;
}

p {
line-height: 24px;
font-weight: 400;
font-size: 16px;
color: #24292e; }

ul {
margin-top: 0; }

li {
color: #24292e;
font-size: 16px;
font-weight: 400;
line-height: 1.5; }

li + li {
margin-top: 0.25em; }

* {
font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
color: #24292e; }

a:visited {
color: #0366d6; }

h2, h3 {
border-bottom: 1px solid #eaecef;
color: #111;
/* Darker */ }

h1 {
color: black;
border-bottom: 1px solid #eaecef;
}
</style>
</body>
</html>
